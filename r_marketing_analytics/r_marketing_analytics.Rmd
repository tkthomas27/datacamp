---
title: "Marketing Analytics in R: Statistical Analysis"
output: html_notebook
---

## Modeling Customer Lifetime Value with Linear Regression

* Overfitting: fitting to the errors as well
* AIC penalize every additional explantory variable
* AIC minimizing model for comparing models
* stepAIC: automatic model picking

```{r}
# getting an overview of new data
summary(salesData2_4)

# predicting sales
predSales5 <- predict(salesModel2, newdata = salesData2_4)

# calculating mean of future sales
mean(predSales5, na.rm=TRUE)

```

## Churn Prevention in Online Marketing

Logistic regression to predict if a customer is coming back

1. Probability to churn: not easy to predict directly; linear regression gives non-sensical
$$
P(Y=1)
$$

2. Log Odds

$$
log \frac{P(Y=1)}{P(Y = 0)} = \beta_0 + \sum_{p=1}^P \beta_p x_ps
$$

3. Odds

$$
\frac{P(Y=1)}{P(Y = 0)} = e^{ \beta_0 + \sum_{p=1}^P \beta_p x_ps}
$$

4. Probability to Churn: final model; probabilty of target variable

$$
P(Y = 1) = \frac{e^{ \beta_0 + \sum_{p=1}^P \beta_p x_ps}}{1 + e^{ \beta_0 + \sum_{p=1}^P \beta_p x_ps}}
$$

Modeling and model selection
* coefficeint is effect on log odds; can only get sense of direction
* use exp to get effect on odds; coefficeint of 1.49 -> increase odds of subscribing by 49%
* can use `stepAIC` to find best variables in the model

```{r}
# Build logistic regression model
logitModelFull <- glm(PaymentDefault ~ limitBal + sex + education + marriage +
                   age + pay1 + pay2 + pay3 + pay4 + pay5 + pay6 + billAmt1 + 
                   billAmt2 + billAmt3 + billAmt4 + billAmt5 + billAmt6 + payAmt1 + 
                   payAmt2 + payAmt3 + payAmt4 + payAmt5 + payAmt6, 
                family = binomial, data = defaultData)

# Take a look at the model
summary(logitModelFull)

# Take a look at the odds
coefsexp <- coef(logitModelFull) %>% exp() %>% round(2)
coefsexp



library(MASS)
# The old (full) model
logitModelFull <- glm(PaymentDefault ~ limitBal + sex + education + marriage +
                   age + pay1 + pay2 + pay3 + pay4 + pay5 + pay6 + billAmt1 + 
                   billAmt2 + billAmt3 + billAmt4 + billAmt5 + billAmt6 + payAmt1 + 
                   payAmt2 + payAmt3 + payAmt4 + payAmt5 + payAmt6, 
                 family = binomial, defaultData)

#Build the new model
logitModelNew <- stepAIC(logitModelFull,trace = 0) 

#Look at the model
summary(logitModelNew) 

# Save the formula of the new model (it will be needed for the out-of-sample part) 
formulaLogit <- as.formula(summary(logitModelNew)$call)
formulaLogit
```

### In Sample Modeling and Thresholding
Pseudo $R^2$ Statistics

1. McFadden
$$
R^2 = 1 - \frac{L_{null}}{L_{full}}
$$

2. Cox and Snell
$$
R^2 = 1 - \left(\frac{L_{null}}{L_{full}}\right)^{2/n}
$$

3. Nagelkerke

$$
R^2 = \frac{1 - \left(\frac{L_{null}}{L_{full}}\right)^{2/n}}{1 - L_{null}^{2/n}}
$$

* If $>0.2$ reasonable; $>0.4$ good; $>0.5$ very good


Accuracy: predict values and find difference; confusion matrix
* look at classification broken down by groups
* expected payoffs: find optimal threshold

```{r}
# see different R2 numbers
library(descr)
LogRegR2(logitModelNew)



# Make predictions using the full Model
defaultData$predFull <- predict(logitModelFull, type = "response", na.action = na.remove)

# Construct the in-sample confusion matrix
confMatrixModelFull <- confusion.matrix(defaultData$PaymentDefault,defaultData$predFull, threshold = 0.5)
confMatrixModelFull

# Calculate the accuracy for the full Model
accuracyFull <- sum(diag(confMatrixModelFull)) / sum(confMatrixModelFull)
accuracyFull



# Calculate the accuracy for 'logitModelNew'
# Make prediction
defaultData$predNew <- predict(logitModelNew, type = "response", na.action = na.remove)

# Construct the in-sample confusion matrix
confMatrixModelNew <- confusion.matrix(defaultData$PaymentDefault, defaultData$predNew, threshold = 0.5)
confMatrixModelNew

# Calculate the accuracy...
accuracyNew <- sum(diag(confMatrixModelNew)) / sum(confMatrixModelNew)
accuracyNew

# and compare it to the full model's accuracy
accuracyFull

```

Payoff Matrix
```{r}
library(SDMTools)
# Prepare data frame with threshold values and empty payoff column
payoffMatrix <- data.frame(threshold = seq(from = 0.1, to = 0.5, by = 0.1),
                           payoff = NA) 
payoffMatrix 
 
for(i in 1:length(payoffMatrix$threshold)) {
  # Calculate confusion matrix with varying threshold
  confMatrix <- confusion.matrix(defaultData$PaymentDefault,
                defaultData$predNew, 
                threshold = payoffMatrix$threshold[i])
  # Calculate payoff and save it to the corresponding row
  payoffMatrix$payoff[i] <- confMatrix[1,1]*250 + confMatrix[1,2]*(-1000)
}
payoffMatrix
```



### Out of sample validation and cross validation
```{r}
# Split data in train and test set
set.seed(534381) 
defaultData$isTrain <- rbinom(nrow(defaultData), 1, 0.66)
train <- subset(defaultData, defaultData$isTrain == 1)
test <- subset(defaultData, defaultData$isTrain  == 0)

logitTrainNew <- glm(formulaLogit, family = binomial, data = train) # Modeling
test$predNew <- predict(logitTrainNew, type = "response", newdata = test) # Predictions




# Out-of-sample confusion matrix and accuracy
confMatrixModelNew <- confusion.matrix(test$PaymentDefault, test$predNew, threshold = 0.3) 
sum(diag(confMatrixModelNew)) / sum(confMatrixModelNew) # Compare this value to the in-sample accuracy

library(boot)
# Accuracy function
costAcc <- function(r, pi = 0) {
  cm <- confusion.matrix(r, pi, threshold = 0.3)
  acc <- sum(diag(cm)) / sum(cm)
  return(acc)
}

# Cross validated accuracy for logitModelNew
set.seed(534381)
cv.glm(defaultData, logitModelNew, cost = costAcc, K = 6)$delta[1]
```

## Survival Analysis in Customer Relationship Management

* censored data: customer data ends because we can't see what happens; kind of missing data; not suitable for logistic regression
* survival analysis: time to event; no loss of information due to; deeper insights --> when will happen not just if
* censoring: random type 1 censoring; churn can't know if it will happen in the future, only when it happens
* for surival analysis need: time under observation and status at end of time

```{r}
# Look at the head of the data
head(dataNextOrder)

# Plot a histogram
ggplot(dataNextOrder) +
  geom_histogram(aes(x = daysSinceFirstPurch,
                     fill = factor(boughtAgain))) +
  facet_grid( ~ boughtAgain) + # Separate plots for boughtAgain = 1 vs. 0
  theme(legend.position = "none") # Don't show legend
```

### Survival curev analysis by Kaplan Meier

* create survival object
* survival function: prob that customer will not churn leading upt to time point t
* hazard function: prob that customer will have churned leading up to t
* hazard rate: prob that customer will churn in small interval around time t given event has not yet happened
* surviavl function is not known; need to estimate; censoring makes it more complicated
* Kaplan Meier takes into those at risk (those who haven't but might)

```{r}
text <- c("hello :) :D ;( yes :cake:")

```


